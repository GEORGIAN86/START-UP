{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-18T20:54:19.059850Z",
     "iopub.status.busy": "2025-06-18T20:54:19.059575Z",
     "iopub.status.idle": "2025-06-18T20:54:20.308799Z",
     "shell.execute_reply": "2025-06-18T20:54:20.308201Z",
     "shell.execute_reply.started": "2025-06-18T20:54:19.059825Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T20:54:27.264961Z",
     "iopub.status.busy": "2025-06-18T20:54:27.264297Z",
     "iopub.status.idle": "2025-06-18T20:54:28.012608Z",
     "shell.execute_reply": "2025-06-18T20:54:28.012063Z",
     "shell.execute_reply.started": "2025-06-18T20:54:27.264936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne import Epochs , pick_types\n",
    "\n",
    "tmin, tmax = -1.0, 5\n",
    "\n",
    "def make_epochs(edf_file  , preload = True) :\n",
    "    raw = mne.io.read_raw_edf( edf_file , preload=True)\n",
    "    # print(raw.info['sfreq'])\n",
    "    raw.filter(7.0, 40.0, fir_design=\"firwin\", skip_by_annotation=\"edge\")\n",
    "    picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")\n",
    "    data, times = raw.get_data(return_times=True)\n",
    "    epochs = Epochs(\n",
    "                    raw,\n",
    "                    tmin=tmin,\n",
    "                    tmax=tmax,\n",
    "                    proj=True,\n",
    "                    picks=picks,\n",
    "                    baseline=None,\n",
    "                    preload=True,\n",
    "             )\n",
    "    return epochs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T20:54:32.364648Z",
     "iopub.status.busy": "2025-06-18T20:54:32.364246Z",
     "iopub.status.idle": "2025-06-18T20:55:36.197149Z",
     "shell.execute_reply": "2025-06-18T20:55:36.196323Z",
     "shell.execute_reply.started": "2025-06-18T20:54:32.364624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "X = []\n",
    "path = Path('/kaggle/input/eeg-open-source/files')\n",
    "all_files = sorted(path.iterdir())\n",
    "half_files = all_files[:len(all_files) // 2]\n",
    "\n",
    "class_1 = []\n",
    "class_2 = []\n",
    "class_3 = []\n",
    "class_4 = []\n",
    "\n",
    "\n",
    "for file in tqdm(half_files, desc=\"Processing directories\"):\n",
    "    if file.is_dir():\n",
    "\n",
    "        \n",
    "        for edf_file in sorted(file.iterdir()):\n",
    "            \n",
    "            if edf_file.name.endswith('.edf') and not edf_file.name.endswith(('01.edf', '02.edf')):\n",
    "                \n",
    "\n",
    "                # (open and close left or right fist)\n",
    "                if edf_file.name.endswith(('03.edf', '07.edf' , '11.edf')):\n",
    "                    data = make_epochs( edf_file = edf_file )\n",
    "                    class_1.append(data)\n",
    "\n",
    "                # (imagine opening and closing left or right fist)\n",
    "                if edf_file.name.endswith(('04.edf', '08.edf' , '12.edf')):\n",
    "                    data = make_epochs( edf_file = edf_file )\n",
    "                    class_2.append(data)\n",
    "\n",
    "                # (open and close both fists or both feet)\n",
    "                if edf_file.name.endswith(('05.edf', '09.edf' , '13.edf')):\n",
    "                    data = make_epochs( edf_file = edf_file )\n",
    "                    class_3.append(data)\n",
    "                    \n",
    "                # (imagine opening and closing both fists or both feet)\n",
    "                if edf_file.name.endswith(('06.edf', '10.edf' , '14.edf')):\n",
    "                    data = make_epochs( edf_file = edf_file )\n",
    "                    class_4.append(data)\n",
    "                    \n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T20:55:37.583240Z",
     "iopub.status.busy": "2025-06-18T20:55:37.582981Z",
     "iopub.status.idle": "2025-06-18T20:55:37.590236Z",
     "shell.execute_reply": "2025-06-18T20:55:37.589561Z",
     "shell.execute_reply.started": "2025-06-18T20:55:37.583221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(class_1[1].get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T20:55:40.761182Z",
     "iopub.status.busy": "2025-06-18T20:55:40.760514Z",
     "iopub.status.idle": "2025-06-18T20:55:49.553991Z",
     "shell.execute_reply": "2025-06-18T20:55:49.553317Z",
     "shell.execute_reply.started": "2025-06-18T20:55:40.761154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "ref_shape = class_1[0].get_data().shape[1:]\n",
    "data_array = []\n",
    "\n",
    "valid_data = [e.get_data()[:-1] for e in class_1 if e.get_data().shape[1:] == ref_shape]\n",
    "data_array.append(np.vstack(valid_data))\n",
    "del class_1\n",
    "del valid_data\n",
    "\n",
    "valid_data = [e.get_data()[:-1] for e in class_2 if e.get_data().shape[1:] == ref_shape]\n",
    "data_array.append(np.vstack(valid_data))\n",
    "del class_2\n",
    "del valid_data\n",
    "\n",
    "valid_data = [e.get_data()[:-1] for e in class_3 if e.get_data().shape[1:] == ref_shape]\n",
    "data_array.append(np.vstack(valid_data))\n",
    "del class_3\n",
    "del valid_data\n",
    "\n",
    "valid_data = [e.get_data()[:-1] for e in class_4 if e.get_data().shape[1:] == ref_shape]\n",
    "data_array.append(np.vstack(valid_data))\n",
    "del class_4\n",
    "del valid_data\n",
    "\n",
    "print(len(data_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T20:55:54.665956Z",
     "iopub.status.busy": "2025-06-18T20:55:54.665330Z",
     "iopub.status.idle": "2025-06-18T20:55:54.670750Z",
     "shell.execute_reply": "2025-06-18T20:55:54.670139Z",
     "shell.execute_reply.started": "2025-06-18T20:55:54.665930Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "count = 0 \n",
    "y = [ [ count ]*data_point.shape[0] for count , data_point in enumerate( data_array )  ]\n",
    "\n",
    "X = np.vstack(data_array)\n",
    "Y = [label for sublist in y for label in sublist]\n",
    "Y = np.array(Y)\n",
    "X = X.transpose(0, 2, 1)\n",
    "\n",
    "X = X * 1e7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T20:56:26.892215Z",
     "iopub.status.busy": "2025-06-18T20:56:26.891553Z",
     "iopub.status.idle": "2025-06-18T21:17:26.449200Z",
     "shell.execute_reply": "2025-06-18T21:17:26.448355Z",
     "shell.execute_reply.started": "2025-06-18T20:56:26.892184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "def setup_filters(sampling_rate):\n",
    "    b_notch, a_notch = signal.iirnotch(50.0 / (0.5 * sampling_rate), 30.0)\n",
    "    b_bandpass, a_bandpass = signal.butter(4, [0.5 / (0.5 * sampling_rate), 30.0 / (0.5 * sampling_rate)], 'band')\n",
    "    return b_notch, a_notch, b_bandpass, a_bandpass\n",
    "\n",
    "def process_eeg_data(data, b_notch, a_notch, b_bandpass, a_bandpass):\n",
    "    data = signal.filtfilt(b_notch, a_notch, data)\n",
    "    data = signal.filtfilt(b_bandpass, a_bandpass, data)\n",
    "    return data\n",
    "\n",
    "def calculate_psd_features(segment, sampling_rate):\n",
    "    f, psd_values = signal.welch(segment, fs=sampling_rate, nperseg=len(segment))\n",
    "    bands = {'alpha': (8, 13), 'beta': (14, 30), 'theta': (4, 7), 'delta': (0.5, 3)}\n",
    "    features = {}\n",
    "    for band, (low, high) in bands.items():\n",
    "        idx = np.where((f >= low) & (f <= high))\n",
    "        features[f'E_{band}'] = np.sum(psd_values[idx])\n",
    "    features['alpha_beta_ratio'] = features['E_alpha'] / features['E_beta'] if features['E_beta'] > 0 else 0\n",
    "    return features\n",
    "\n",
    "def calculate_additional_features(segment, sampling_rate):\n",
    "    f, psd = signal.welch(segment, fs=sampling_rate, nperseg=len(segment))\n",
    "    peak_frequency = f[np.argmax(psd)]\n",
    "    spectral_centroid = np.sum(f * psd) / np.sum(psd)\n",
    "    log_f = np.log(f[1:])\n",
    "    log_psd = np.log(psd[1:])\n",
    "    spectral_slope = np.polyfit(log_f, log_psd, 1)[0]\n",
    "    return {\n",
    "        'peak_frequency': peak_frequency,\n",
    "        'spectral_centroid': spectral_centroid,\n",
    "        'spectral_slope': spectral_slope\n",
    "    }\n",
    "\n",
    "# Setup\n",
    "sampling_rate = 160\n",
    "b_notch, a_notch, b_bandpass, a_bandpass = setup_filters(sampling_rate)\n",
    "\n",
    "df = []\n",
    "\n",
    "for idx, sample in enumerate(tqdm(X, desc=\"Extracting EEG features\")):\n",
    "    sample_features = {}\n",
    "    for ch in range(sample.shape[1]):  # Iterate over 64 channels\n",
    "        channel_data = sample[:, ch]\n",
    "        processed_data = process_eeg_data(channel_data, b_notch, a_notch, b_bandpass, a_bandpass)\n",
    "        \n",
    "        psd_features = calculate_psd_features(processed_data, sampling_rate)\n",
    "        additional_features = calculate_additional_features(processed_data, sampling_rate)\n",
    "\n",
    "        # Prefix channel index to feature names\n",
    "        channel_features = {f'ch{ch}_{k}': v for k, v in {**psd_features, **additional_features}.items()}\n",
    "        sample_features.update(channel_features)\n",
    "    \n",
    "    df.append(sample_features)\n",
    "\n",
    "# Optionally convert to DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T21:29:21.825706Z",
     "iopub.status.busy": "2025-06-18T21:29:21.825111Z",
     "iopub.status.idle": "2025-06-18T21:29:21.830526Z",
     "shell.execute_reply": "2025-06-18T21:29:21.829650Z",
     "shell.execute_reply.started": "2025-06-18T21:29:21.825678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \n",
    "    # TRAINING PARAMS\n",
    "    \"training_size\"    : 0.80,\n",
    "    \"val_size\"         : 0.20,\n",
    "    \"learning_rate\"    : 1e-4,\n",
    "    \"batch_size\"       : 64,\n",
    "    \"training_epochs\"  : 15000,\n",
    "    \"learning_step_size\" : 25,       \n",
    "    \"learning_rate_decay\": 1e-5,        \n",
    "\n",
    "    # TRANSFORMER PARAMS\n",
    "    \"maxlen\"           : 1,  # (Seq_len of Transformer)\n",
    "    \"num_features\"     : 512,   # No. of Electrodes\n",
    "    \"num_classes\"      : 4,\n",
    "    \"num_heads\"        : 8,\n",
    "    \"embed_dim\"        : 64,   # 640 * 14 ----> 640 * embed_dim -----> tranformer  ---> \n",
    "    \"ff_dim\"           : 64    # middle layer ( No. of Nodes )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T21:32:25.769419Z",
     "iopub.status.busy": "2025-06-18T21:32:25.768624Z",
     "iopub.status.idle": "2025-06-18T21:32:25.774519Z",
     "shell.execute_reply": "2025-06-18T21:32:25.773767Z",
     "shell.execute_reply.started": "2025-06-18T21:32:25.769392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data = data.values\n",
    "        if isinstance(labels, pd.Series):\n",
    "            labels = labels.values\n",
    "\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T21:33:30.269188Z",
     "iopub.status.busy": "2025-06-18T21:33:30.268498Z",
     "iopub.status.idle": "2025-06-18T21:33:30.285988Z",
     "shell.execute_reply": "2025-06-18T21:33:30.285299Z",
     "shell.execute_reply.started": "2025-06-18T21:33:30.269162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class EEGTransformerEncoderOnly(nn.Module):\n",
    "    def __init__(self, maxlen, num_features, num_classes, embed_dim, \n",
    "                 num_heads, ff_dim, dropout=0.1, num_encoder_layers=1):\n",
    "        super(EEGTransformerEncoderOnly, self).__init__()\n",
    "        \n",
    "        self.maxlen = maxlen\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        self.input_projection = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, \n",
    "            num_layers=num_encoder_layers\n",
    "        )\n",
    "        \n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(embed_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def positional_encoding(self, x):\n",
    "        \"\"\"Generate positional encoding for the input sequence\"\"\"\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        \n",
    "        pe = torch.zeros(seq_len, d_model, device=x.device)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float, device=x.device).unsqueeze(1)\n",
    "        \n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float, device=x.device) * \n",
    "                            -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        return pe.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.input_projection(x)\n",
    "        # x = x + self.positional_encoding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        # x = x.permute(0, 2, 1)\n",
    "        x = self.global_avg_pool(x).squeeze(-1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def train_model(model, train_loader, val_loader, criterion, optimizer,  \n",
    "                    scheduler ,device = None ,epochs = config['training_epochs']):\n",
    "    \n",
    "        model.to(device)\n",
    "        train_losses, val_losses = [], []\n",
    "        train_accs, val_accs = [], []\n",
    "        # print(\"Train_laoder: \",len(train_loader))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            total_loss, correct, total = 0, 0, 0\n",
    "        \n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                correct += (outputs.argmax(1) == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "        \n",
    "            train_loss = total_loss / total\n",
    "            train_acc = correct / total\n",
    "            val_loss, val_acc = EEGTransformerEncoderOnly.evaluate_model(model, val_loader, criterion)\n",
    "        \n",
    "            print(f\"Epoch {epoch + 1}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.4f}, \"\n",
    "                  f\"Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "        \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)  \n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate_model(model, dataloader, criterion=None):\n",
    "        model.eval()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in dataloader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs )\n",
    "                if criterion:\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    total_loss += loss.item() * inputs.size(0)\n",
    "                correct += (outputs.argmax(1) == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "        if criterion:\n",
    "            return total_loss / total, correct / total\n",
    "        return correct / total\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T21:33:32.343341Z",
     "iopub.status.busy": "2025-06-18T21:33:32.342701Z",
     "iopub.status.idle": "2025-06-18T21:33:32.350145Z",
     "shell.execute_reply": "2025-06-18T21:33:32.349248Z",
     "shell.execute_reply.started": "2025-06-18T21:33:32.343312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def modal(X, Y):\n",
    "\n",
    "    dataset = EEGDataset(X, Y)\n",
    "\n",
    "    train_size = int(config[\"training_size\"] * len(dataset))\n",
    "    val_size = len(dataset) - train_size  # Use the rest for validation\n",
    "\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    model = EEGTransformerEncoderOnly(maxlen=config[\"maxlen\"], num_features=config[\"num_features\"], num_classes=config[\"num_classes\"], \n",
    "                           embed_dim=config[\"embed_dim\"], num_heads=config[\"num_heads\"], ff_dim=config[\"ff_dim\"])\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(train_loader)\n",
    "    print(f\"Number of batches: {num_batches}\")\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(\n",
    "    optimizer, \n",
    "    step_size=config[\"learning_step_size\"],       # e.g., every 10 epochs\n",
    "    gamma=config[\"learning_rate_decay\"]           # e.g., 0.1 for 10x decay\n",
    "        \n",
    "    )\n",
    "\n",
    "    EEGTransformerEncoderOnly.train_model(model, train_loader, val_loader, criterion, optimizer , scheduler , device )\n",
    "\n",
    "    # joblib.dump(model,\"model.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "modal(df,Y)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7624831,
     "sourceId": 12110499,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
